---
layout: page
title: Publications
---
---
## Tracking the Progression of Reading Through Eye-gaze Measurements
<a href = "https://github.com/stevebottos/stevebottos.github.io/blob/master/_downloads/RLS_arxiv_submission.pdf" target = "_blank">Paper Download</a> 
In this paper we consider the problem of tracking the progression of reading through eye-gaze measurements. Such an algorithm is
novel and will ultimately help to develop a method of analyzing eye-gaze data which had been collected during reading activity in order to uncover crucial information regarding the individual’s interest level and quality of experience while reading a passage of text or book. Additionally, such an approach will serve as a “visual signature” — a method of verifying if an individual has indeed given adequate attention to critical text-based information. Further, an accurate “reading-progression-tracker” has potential applications in educational institutions, e-readers and parenting solutions. Tracking the progression of reading remains a challenging problem due to the fact that eye-gaze movements are highly noisy and the eye-gaze is easily distracted in a limited space, like an e-book. In a prior work, we proposed an approach to analyze eye-gaze fixation points collected while reading a page of text in order to classify each measurement to a line of text; this approach did not consider tracking the progression of reading along the line of text. In this paper, we extend the capabilities of the previous algorithm in order to accurately track the progression of reading along each line. the proposed approach employs least squares batch estimation in order to estimate three states of the horizontal saccade: position, velocity and acceleration. First, the proposed approach is objectively evaluated on a simulated eye-gaze dataset. Then, the proposed algorithm is demonstrated on real data collected by a Gazepoint eye-tracker while the subject is reading several pages from an electronic book.
> **Index Terms**: Autonomous Systems, Human-Machine Automation, Human Factors, Eye-Gaze Points, Hidden Markov Models, Least Squares Estimation, Kalman Filter

## Tracking the Progression of Reading Through Eye-gaze Measurements
<a href = "https://github.com/stevebottos/stevebottos.github.io/blob/master/_downloads/HMM_arxiv_submission.pdf" target = "_blank">Paper Download</a> 
In this paper, we consider the problem of tracking the eye-gaze of individuals while they engage in reading. Particularly, we develop ways to accurately track the line being read by an individual using commercially available eye tracking devices. Such an approach will enable futuristic functionalities such as comprehension evaluation, interest level detection, and user-assisting applications like hands-free navigation and automatic scrolling. Existing commercial eye trackers provide an esti- mated location of the eye-gaze fixations every few milliseconds. However, this estimated data is found to be very noisy. As such, commercial eye- trackers are unable to accurately track lines while reading. In this paper we propose several statistical models to bridge the commercial gaze tracker outputs and eye-gaze patterns while reading. We then employ hidden Markov models to parametrize these statistical models and to accurately detect the line being read. The proposed approach is shown to yield an improvement of over 20% in line detection accuracy.
> **Index Terms**: Autonomous Systems, Human-Machine Automation, Human Factors, Eye-Gaze Points, Hidden Markov Models, Eye-Tracking, Cognitive Context Detection
